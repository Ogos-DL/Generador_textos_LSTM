{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas Filtro:\n",
    "\n",
    "- Lenguaje Filtro (Python)\n",
    "- Crear sistema de web scraping, y crear dataset de al menos 5 categorías , con datos obtenidos a       través del web scraping.\n",
    "- Las categorías deben de estar numéricamente balanceadas en cantidad.\n",
    "- Se debe crear un procedimiento automatizado de preprocesamiento .\n",
    "- Se debe desarrollar un modelo de redes neuronales artificiales con tensor flow/keras , para el       procesamiento de este dataset.\n",
    "- Se debe crear una api rest , que proporcione por medio de métodos http , un ingreso de datos y una   salida de la clasificación del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/Alexander_the_Great\"\n",
    "# Realizamos la petición a la web\n",
    "req = requests.get(url)\n",
    "page = urllib.request.urlopen(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statusCode = req.status_code\n",
    "htmlText = req.text\n",
    "print(\"statusCode: \", statusCode)\n",
    "print(\"htmlText  : \", htmlText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos que la petición nos devuelve un Status Code = 200\n",
    "if statusCode != 200:\n",
    "    print(\"Error al solicitar la página\",\"statusCode: \", statusCode)\n",
    "else:\n",
    "    print(\"Ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if statusCode == 200:\n",
    "\n",
    "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
    "    html = BeautifulSoup(req.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the HTML from our URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "div = html.find(id='firstHeading')\n",
    "print(div.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo de captura de subtitulos\n",
    "[item.get_text() for item in html.select(\"h2 .mw-headline\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captura de contenido\n",
    "paragraphs = html.select(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for para in paragraphs:\n",
    "    if cont == 20:\n",
    "        cont = 0\n",
    "        time.sleep(1)\n",
    "    cont +=1    \n",
    "    cont\n",
    "    print (para.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Tareas futuras....\n",
    "\n",
    "- Mejorar el ingreso para hacer dinámico el nombre de la página\n",
    "- Agregar la categoría y guardarlo en una carpeta x categoría...\n",
    "\n",
    "## Categorías\n",
    "\n",
    "1. Edad antigua\n",
    "2. Edad media\n",
    "3. Edad moderna\n",
    "4. Edad contemporánea\n",
    "5. Ninguna\n",
    "\n",
    "\n",
    "- Hay que hacer todo el preprocesamiento de los textos.... recién hecho eso..... podremos empezar a pensar el modelos de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
